<!-- -*- coding: utf-8 -*- -->
... oczywiście *środowiska*.

Skądś się te bodźce biorą i w czymś się te reakcje rozgrywają i na coś oddziałują, co nie? A *ciało*
to, za przeproszeniem, pies? 

Właściwie, jak się tak głębiej zastanowić, środowisko nie jest ani szczególnie małe, ani mało
znaczące. No ale (zdawałoby się, że) środowisko to nie fascynujący i tajemniczy *Umysł*; to tylko w
większości łatwo obserwowalne, znane nam wszystkim i przez wszystkich niepsychopatów kochane sklepy
Żabka, jakieś ulice, przystanki i auta, przechodnie i kierowcy, 

a ci przechodnie

czasami

na polowaniu? 

z psami

Poza tym dużo wody, ziemi i powietrza, no i zieleni i czerwieni, rozmaitego szumu, i to by było w
zasadzie na tyle, bo powiedzmy sobie szczerze, że "écru wpadające w limonkę" to nie kolor, tylko
stan chorego umysłu, a właściwie rozumiana ryba jest praktycznie
[warzywem](https://youtu.be/MPY_EuvimH0?si=XMt5bmJatCwwfAJs).

## Sposób trzeci, też śmieszniejszy, ale to już nie jest taki oczywisty żart

Jednym z brzemiennych dla mnie w skutki zdarzeń było odkrycie - zdaje się, że w trakcie tych dwóch
lat codziennego uczenia się różnych rzeczy, o których wspominałem we wprowadzeniu - w czytelni
anglojęzycznej Instytutu Psychologii UJ książki [*An Introduction to Reinforcement
Learning*](https://archive.org/details/rlbook2018/mode/2up) Suttona i Barto ([pierwsze
wydanie](http://incompleteideas.net/book/the-book-1st.html) nie jest może tak aktualne jak drugie,
ale też jest wspaniale napisane i jest znacznie krótsze, przez co szybciej wchodzi). Będzie chyba
lepiej, jeśli zanim zacznę o tym gadać, oddam głos tym dwóm cudownym autorom i moim zdaniem (z
konieczności lokalnie, ale jednak) głębokim, wytrawnym i diabelnie przenikliwym myślicielom.

Już z samej obwoluty możemy się dowiedzić, że (cytaty pochodzą z wydania pierwszego) ...

> This introductory textbook on reinforcement learning is targeted toward engineers and scientists
> in artificial intelligence, operations research, neural networks, and control systems, and we hope
> it will also be of interest to psychologists and neuroscientists.

... się chłopaki przeliczyły. Bo niestety większość współczesnych psychologów zajmuje się głównie
uprawianiem nauki [*performatywnej*](https://en.wikipedia.org/wiki/Cargo_cult), ktora pasie się na
ogól z dala od technicznie złożonych tekstów czy autentycznego i systematycznego uczenia się
właściwie czegokolwiek. Ale miałem tyle nie gadać.

<br>

Już nic nie mówię.

Zamieniam się w Króla Ciszy.

Czy potrafię *usłyszeć* ironię? Chyba tak, a czemu?

Albo wiesz co, może jednak zacznę od omówienia trzech przykładów.

## Brudna robota

Wyobraź sobie proszę, że jesteś n-ręką bandytką. Już wyjaśniam.

Zadanie n-rękiej bandytki to wyidealizowana wersja lubianej przez niektórych zabawy, polegającej na
tym, że siedzimy lub stoimi przed takim sporym pudłem, ciągniemy za wystającą z prawej strony
wajchę, po czym patrzymy na zmieniające się w kilku okienkach obrazki i rujnujemy sobie i swoim
ewentualnym bliskim życie. Co ciekawe, wiele osób jest najwyraźniej zdania, że adekwatnym
określeniem dla tej dualnie urzekającej formy spędzania wolnego czasu jest słowo "ekscytująca".

Funkcjonalnie, chodzi tu oczywiście o skończony (`n : Nat`) ...

1. zbiór dostępnych działań (`d : Dzialanie`), ...

2. które można wykonywać teoretycznie w nieskończoność (`iteracja : Nat → Dzialanie`) ...

3. i po których następuje cokolwiek, co można ocenić (`Dzialanie × Stan × Stan → Nagroda`), ...

4. posługując się dowolną relacją porządku (`[Porzadek Nagroda]` \{przypominam, że to jest powołanie
   się na instancję klasy o nazwie `Porzadek`\}).

Funkcja nagrody ma taką złożoną strukturę, bo w tej wersji jest zwykle najwygodniejsza w
użyciu. Chodzi tu o to, że to, jak dobrze lub źle się dzieje może w ogólnym przypadku zależeć nie
tylko od stanu, w którym wykonuje się jakieś działanie, ale także od stanu, do którego się trafia po
wykonaniu tego działania, a czasem również od działania. Na przykład, przykrość związana ze
złamaniem nogi po próbie przeskoczenia zbyt wielu schodów na raz jest funkcją początkowej wysokości
(własność stanu wyjściowego), kosztów wykonania skoku (koszt ruchu) i kosztów złamania nogi (stan
docelowy).

Wyobraź sobie jeszcze, że masz nieskończenie dużo czasu, za to ani nie masz znajomych, ani w ogóle
nic innego do roboty, `n = 3`, a nagrodami, jak to w kasynie, są wypłaty pieniężne, które mimo tej
szczególnej sytuacji nadal sobie cenisz. Załóżmy dalej, że zaczęłaś od jednokrotnego sprawdzenia
każdego z dostępnych działań:

```lean
-- Ten parametryczny typ pozwala wygodnie rozumować na temat czegoś, co może być niedostępne, 
-- niepoznawalne, lub bezużyteczne. W Leanie ten typ nazywa się `Option` i ma konstruktory o nazwach
-- `none` i `some`, ale poza tym to (funkcjonalnie) to samo.
inductive Co? (α : Type u) where
  | a_nic         : Co? α
  | a_to (to : α) : Co? α

open Co?

-- 0 ↦ 0, 1 ↦ 1, 2 ↦ 2, _ ↦ przepraszam, ale właśnie zaczął mi się urlop.
def odwazny_poczatek (n : Nat) : Co? Nat :=
    if n < 3 then (a_to n) else a_nic
```

Przypuszczam, że nie muszę tłumaczyć sposobu działania wyrażeń o postaci `if <warunek> then <term>
else <term>`, może poza jedną subtelnością: Żeby Lean to zaakceptował, term `warunek` musi być
*zdaniem rozstrzygalnym*, co znaczy, że Lean musi być w stanie znaleźć dowód prawdziwości albo
fałszywości tego zdania.

Reguła działania jest tu taka prosta między innymi dlatego, że traktujemy tą sytuację, a dokładniej
to zadanie, jakby nie miało *stanu*. Mówiąc inaczej, ale funkcjonalnie równoważnie, istnieje tylko
jeden stan tego (zewnętrznego wobec nas?) świata. A stąd wynika, że wszystko działa zawsze tak samo,
niezależnie od tego, co się wcześniej wydarzyło.

Widzimy więc znowu, że w pewnych sytuacjach singleton (tutaj możliwych stanów) zachowuje się tak,
jak będący jego dualnym odpowiednikiem zbiór pusty. W tym przypadku dlatego, że pojęcie stanu:
struktury, świata, sytuacji, czy zadania, jest tylko wtedy użyteczne, kiedy stany mogą być różne. A
mówiąc inaczej, ale w zasadzie to samo, pojęcie stanu domaga się, przynajmniej potencjalnej, tego
rodzaju różnorodności, bo kanonicznym zastosowaniem tego pojęcia jest, cóż, rozróżnianie stanów.

No więc wyobraź sobie, że na początku zastosowałaś `n = 3` razy zdefiniowaną wyżej *strategię
eksploracyjną*, uzyskując takie oto (funkcjonalnie) zyski, będące jednocześnie (funkcjonalnie)
jedynymi dostępnymi informacjami na temat dynamiki tego środowiska (i zarazem zadania):

`0 ↦ 665, 1 ↦ 664, 2 ↦ 667`

W tym wypadku możemy jednoznacznie i autorytatywnie stwierdzić, co *powinnaś* zrobić, bo to wynika z
definicji, a wynika z niej właśnie dlatego, że to jest definicja zadania. Stwierdzenie, że coś się
powinno, albo że czegoś się nie powinno, ma sens *tylko* zakładając jakiś cel, normę, albo wartość,
czyli ostatecznie jakiś cel, a ponieważ cel jako taki jest zawsze pewną preferencją, czyli oceną, a
ocena jako taka jest zawsze jakąś postawą, funkcjonalnie równoważną pewnej relacji porządku, czyli
ostatecznie punktem widzenia, założenie na temat celu jest
[*nieuzasadnialne*](https://pl.wikipedia.org/wiki/Gilotyna_Hume%E2%80%99a) inaczej niż ze względu na
jakieś inne cele (czyli jakieś preferencje, postawy, oceny, wartości, czy normy, a formalnie relacje
porządku). Mówiąc krócej i konkretniej:

*Jeżeli* zależy Ci tylko na pieniądzach, to zgodnie z dostępnymi danymi, *powinnaś* wybrać `2`,
ponieważ *najlepszym*, albo *racjonalnym*, albo *poprawnym*, a może nawet *jedynym sensownym*
wyborem jest w tej sytuacji `2` i tylko `2`.

Zwróć proszę uwagę, że *racjonalny* znaczy tu *dokładnie* to samo, co *najlepszy*, a najlepszy
znaczy *dokładanie* to samo, co *największy* ze względu na relację porządku, która odpowiada celowi.

Co równie ważne, z Twojej perspektywy *rozstrzygnięcie*, który wybór jest w danym momencie
najlepszy/racjonalny/poprawny wymaga skorzystania z *pamięci*, która przyjęła tutaj *maksymalnie
uniwersalną* postać *sekwencji reakcji*.

Akurat w tym przykładzie reakcja jest *parą* złożoną z bodźca i działania, ale w ogólnym przypadku
reakcja jako taka będzie (funkcjonalnie) *trójką*, złożoną z ...

1. bodźca, inaczej *sygnału*, czyli funkcjonalnie (zwykle ekstremalnie fragmentarycznej i lokalnej)
*informacji na temat aktualnego stanu* (świata), ...

2. działania - a moim zdaniem lepiej *ruchu* - wykonanego w danej *próbie* ...

3. i stanu *całego* (ale za to tylko rozważanego, a więc może być przynajmniej subiektywnie mały)
   *świata*.

Zwracam też uwagę, że mówimy tu o środowisku, celach, sygnałach stanu i działaniach albo ruchach
"widocznych" *z perspektywy*, potencjalnie czysto hipotetycznej, *wszechwiędzącej obserwatorki*.

## Imperator R

Zmienimy teraz język na taki, który [wymaga](https://pl.wikipedia.org/wiki/Odzie%C5%BC_ochronna)
założenia co najmniej rękawic do smaru i oleju. I okularów ochronnych. Zresztą maska przeciwpyłowa
też by nie zaszkodziła. Będzie to mianowicie używany przez wielu psychologów zajmujących się (często
niestety dosyć nieudolnie) analizą danych język imperatywny
[R](https://pl.wikipedia.org/wiki/R_(j%C4%99zyk_programowania)).

Zaczniemy od zdefiniowania w nim prostej *funkcji środowiska*:

```r
## Ta funkcja będzie chwilowo naszym modelem środowiska, w którym przede wszystkim: może być lepiej
## lub gorzej, a to, jak w nim (jakimś nam) jest, ma (jakiś) związek z tym, jakie (jacyś my)
## wykonujemy ruchy.
E = function(a){
    c(665, 664, 667)[a + 1]
}
```

Nasza prosta funkcja środowiska pobiera tylko indeks (albo po prostu numer) ruchu (albo po prostu
ruch), a *potencjalnie* - bo to, czy można takie ruchy nazwać decyzjami, zależy od tego, jak to
wszystko razem działa - decyzję, której wartościami mogą być liczby naturalne od 0 do 2. W ciele tej
funkcji, zdefiniowanym między nawiasami klamrowymi, widzimy wyrażenie (`c(...)`) tworzące *wektor*
trójelementowy, czyli pewną sekwencję, której wartościami są nagrody/sygnały, odpowiadające każdemu
z ruchów/działań. Na tym wektorze wykonywana jest operacja indeksowania, czyli wskazywania elementu
sekwencji za pomocą liczby naturalnej, którą to operację oznaczamy w większości powszechnie
używanych języków używając nawiasów kwadratowych. Ponieważ jednak w R indeksujemy elementy należące
do sekwencji zaczynając od 1, a nie - jak w tych bardziej cywilizowanych językach - od 0, do indeksu
działania dodajemy najpierw 1.

xR jest (interpretowanym) językiem imperatywnym, dlatego `E` to tutaj *zmienna*, która będzie nazwą
funkcji środowiska dopiero od momentu, w którym poddamy ten fragment kodu ewaluacji. W
przeciwieństwie do Leana, napisany w skrypcie R-a kod nie zaczyna więc "od razu działać". Widzimy
też, że nie ma tu żadnych jawnych informacji o typach danych, bo (ubogi) system typów R-a został
zaprojektowany do realizacji innych celów niż formalizacja całej matematyki.

Jeżeli teraz w *wierszu poleceń* interpretera języka R (`> ...`), którego w Leanie nie ma, bo
interakcja z Leanem nie polega na wykonywaniu pętli [REPL](https://pl.wikipedia.org/wiki/REPL),
napiszemy `E(1)` i naciśniemy Enter, zobaczymy następującą odpowiedź funkcji środowiska:

```r
> E(1)
[1] 664
```

Taki komunikat **czytamy jako**: Sie robi, szefowo (bo R jest interpreterem pochodzenia wiejskiego,
ale w dobrym znaczeniu), oto wektor jednoelementowy (`[1]`), zawierający liczbę `664`.

## Najprościej, jak się da, żeby zobaczyć, co się da

Ze względu na kwestie, które staramy się teraz naświetlić, nie jest jednak ważne, czy mamy do wyboru
trzy ruchy, czy dwa, byle tylko był możliwy jakiś wybór. Wobec tego dokonamy uproszczenia i
pozbędziemy się jednej z alternatyw, tym bardziej, że zbiory dwuelementowe mają dla nas głębsze, o
ile nie zbyt (?) głębokie znaczenie. Nie będziemy się też bawić w mapowanie *indeksów* ruchów na
*same* ruchy, bo to w tym przypadku (funkcjonalnie) jedno i to samo.

Żeby napisać funkcję, która w jakiś sensowny sposób gra w tą grę, *musimy* skorzystać z *pamięci*. Z
powodów, które staną się jasne niebawem, rozwiążemy ten problem w stylu, który bardziej przypomina
ten stosowany w językach funkcyjnych niż imperatywnych:

```r
## Tu określamy, gdzie są jakie
konfitury = c(42, 75)

## To jest odtąd nasz (kolejny) model środowiska rozumianego jako pewne zadanie, a więc środowiska w
## którym to, jak jest nam w danym momencie dobrze albo źle, zależy (w ogólnym przypadku być może
## tylko między innymi) od wykonanego ruchu.
E = function(a){
    konfitury[a]
}

## A to jest funkcja "podmiotki", inaczej "agentki". Przyjmujemy tutaj, że agentka nie odbiera
## początkowo żadnego sygnału ze środowiska (`sygnal = NA`), jej pamięć jest pusta, kondycja ma
## poziom wyjściowy, i jest najmłodszą możliwą wersją siebie.
A = function(sygnal = NA, ## To są domyślne wartości parametrów tej funkcji, ...
             pamiec = c(NA, NA),
             wypas  = 0,
             zycia  = 9){ ## ... a to jej ciało:
    ##
    ## Etap wyboru ruchu:
    if(is.na(sygnal)){
        ## Jeżeli nie ma informacji na temat ostatniego sygnału, to musi to być pierwsza próba, w
        ## której arbitralnie wybieramy pierwszy ruch.
        ruch = 1
    }else{
        ## Jeżeli natomiast to nie jest początek interakcji ze środowiskiem, ...
        if(zycia == 0){
            ## ... ale to ostatnie życie, to oddajemy wszystko, co nam zostało, ...
            print("Cześć, i dzięki za ryby")
            return(wypas)
        }else{
            ## ... a jeżeli to nie jest ostatnie życie, ...
            if(any(is.na(pamiec))){
                ## ... to jeżeli nie ma jeszcze zapisu pamięciowego wartości sygnału po którymś ruchu, to
                ## wybieramy pierwszy taki ruch, ...
                ruch = which(is.na(pamiec))[1]
            }else{
                ## ... w przeciwnym razie wybieramy ruch o największym zapamiętanym sygnale:
                ruch = which(pamiec == max(pamiec))[1]
            }
        }
    }
    ## Etap przetwarzania sygnału:
    ##
    ## Odbieramy sygnał ze środowiska ...
    sygnal = E(ruch)
    ## .. i oddajemy się konsumpcji:
    wypas = wypas + sygnal
    ## Skonsumowawszy otrzymany właśnie sygnał, zapamiętujemy go jako własność wykonanego ruchu, ...
    pamiec[ruch] = sygnal
    ## ... a następnie - trochę się od tego starzejąc - ...
    zycia = zycia - 1
    ## ... aplikujemy Się do dostępnych danych:
    A(sygnal, pamiec, wypas, zycia)
}

A()
```

Cały ten kod możesz wkleić na przykład [tutaj](https://rdrr.io/snippets/), albo do wcześniej
zainstalowanego, dostępnego za darmo interpretera języka R. Po wykonaniu ewaluacji (albo po
*u-ruchomieniu*) tego kodu przekonasz się, że - jak można policzyć (ale komu by się chciało) - po
pierwszych dwóch wyborach eksploracyjnych ta agentka wybiera już do samego końca ruch, po którym
występuje największy sygnał nagrody:

```r
> A()
[1] "Cześć, i dzięki za ryby"
[1] 642
```

<hr>

**Przypomnienie o fundamentalnej różnicy między językami funkcyjnymi i imperatywnymi**: W języku R,
symbole takie jak tutaj `E`, `A`, `konfitury`, `sygnal`, czy `ruch` nie są *stałymi*, tylko
zmiennymi, które w dodatku mają *inny* charakter niż zmienne w Leanie. Zmienne w Leanie są *tylko
nazwami wejść* (czystych) *funkcji*, a zmienne w R są *nazwami miejsc w pamięci komputera*, w
dodatku *nie* mają raz na zawsze ustalonego typu. Dlatego *w każdej chwili* można *przypisać* - za
pomocą operacji tylko *wyglądającej* jak równość matematyczna - na przykład do zmiennej `E`,
*jakąkolwiek* wartość. Zależnie od kontekstu, zastosowanie operacji `=`, którą możemy oznaczać w R
również za pomocą symbolu `<-`, jest więc albo *nadaniem* wartości zmiennej, albo jej *zmianą*.

Między innymi dlatego, że ciała funkcji napisanych w R mogą korzystać z dowolnych widocznych w tych
ciałach zmiennych, w tym również ze zmiennych *globalnych*, a wartości zmiennych w R mogą się
zmieniać w trakcie działania programu, funkcje w R mogą mieć i często mają *skutki uboczne*. To
znaczy, że nie muszą zwracać i często nie zwracają tych samych wartości dla tych samych
wejść. Wynika stąd, że funkcje w R zachowują się często jak *procesy fizyczne*, a nie jak "procesy"
*logiczne* (inaczej matematyczne).

Kod napisany w R to jednak *również* matematyka. *Możemy* dowodzić twierdzeń dotyczących sposobu
działania kodu napisanego w językach imperatywnych, bo te języki są formalne, co znaczy, że napisane
w nich programy działają zgodnie z jednoznacznymi, sztywnymi zasadami, a zatem zgodnie z jakąś
logiką. Różnica polega na tym, że dowodzenie twierdzeń na temat działania programów napisanych w
językach imperatywnym może wymagać uwzględnienia modelu komputera kontrolowanego przez tego rodzaju
programy, a czasem nawet modelu świata, z którym wykonujący je komputer wchodzi w interakcję. A to z
kolei wymaga zastosowania logiki (równoważnej logice) *przyczynowej* (którą poznamy kiedy indziej),
co też nie powinno nikogo dziwić, bo w określeniu "skutek uboczny" jest przecież, jak byk (ale w
dobrym sensie) słowo (sąsiadujące ze słowem) "uboczny".

To ja już może odprowadzę się do drzwi.

<hr>

Nasza (domniemana) agentka rodzi się w tym świecie z bazową "kondycją" (domyślna wartość
zmiennej/parametru/argumentu `wypas` to 0). Częściowo wewnątrz (ciała) agentki (jako funkcji)
zdeterminowana jest również - jako przekształcana w ciele, początkowa wartość jednej ze zmiennych -
długość jej "życia". Można więc powiedzieć, że ta agentka rodzi się z wbudowanym "zegarem
biologicznym", który resetuje się do wartości "fabrycznej", kiedy wydaje z siebie pierwotny krzyk
(`A()`). Domyślna, a więc tutaj tylko początkowa wartość sygnału ze środowiska to `NA`, co w języku
R jest standardowym oznaczeniem braku danych (ang. *Not Available*). Czyli "rodzi się z zamkniętymi
oczami".

Mogłoby się więc wydawać, że rodzi się jako *tabula rasa*, ale to tylko złudzenie, wynikające z
naiwnego, wąskiego rozumienia takich pojęć jak *pamięć* i *wiedza*. W szczególności, pamięć jest tu
co prawda początkowo pusta, ale jest *dwu*komórkowa, a to znaczy, że jej struktura jest "od
urodzenia" *dopasowana do zadania*.

Można powiedzieć, że już samo to jest czymś w rodzaju wbudowanej (uogólnionej) *wiedzy*. Wiedza musi
być w jakiś sposób zapisana fizycznie, a tym, co czyni własność fizyczną (funkcjonalną) wiedzą jest
*możliwość wnioskowania* z tej własności w połączeniu z *wiedzą o tej możliwości* (tak, to jest
*funkcjonalna definicja rekurencyjna*). Bo nie może być naszą wiedzą coś, o czym nie wiemy, że to
wiemy. Ta akurat wbudowana funkcjonalność też jest wiedzą, tylko w ogólniejszym sensie, bo chociaż
ta agentka nie *wyprowadza wniosków* z tej własności, to jednak ona sama - to jest ta *agentka* -
*jest* (między innymi) *wnioskowaniem* z tej własności, bo (ze względu na to zadanie) *jest
racjonalnym*, a więc też *logicznym sposobem użycia* pamięci dwukomórkowej.

Zastanawiasz się nadal, co to za zagadkowo uogólnione pojęcia wiedzy, pamięci i wnioskowania? Otóż
*struktura* (ciała \{funkcji\}) tej agentki jest (między innymi) pewnym *modelem zadania*!

W szczególności, zarówno *konstrukcja* jak i *sposób działania* tej funkcji są dopasowane do
jednoznacznie określonego celu (maksymalizacja skonsumowanej sumy konfitur) i do dynamiki
środowiska. Właściwie jedyna wbudowana "niepewność", to brak wbudowanej w jakikolwiek sposób
(uogólnionej) wiedzy na temat konkretnych wartości sygnałów następujących po każdym z dostępnych
ruchów. Dlatego ta agentka nie musi się prawie w ogóle *uczyć* i dlatego będzie dla nas pouczającym
punktem wyjścia dla rozważań na temat sensu życia.

## Zawładnięcie przez wchłonięcie[^1]

Jeżeli pozbędziemy się z kodu śladów *intencji autora* (czyli w tym wypadku mnie), zastępując
deksryptywne nazwy zmiennych abstrakcyjnymi symbolami, i usuniemy z ciała funkcji co tylko się da,
uzyskamy *C*zystą *A*gen*t*kę:

```r
f = function(X = c(NA, NA))
    ifelse(any(is.na(X)), which(is.na(X)), which(X == max(X)))

g = function(X, Y, Z = NA)
    if(X == 1){ c(Z, Y[2]) }else{ c(Y[1], Z) }

CAt = function(X = NA, Y = c(NA, NA), Z = 0, V = 9)
    if(V > 1){ CAt(E(f(Y)), g(f(Y), Y, E(f(Y))), Z + E(f(Y)), V - 1)
    }else{ Z + X }

CAt()
```

Ta agentka działa tak samo, jak agentka omawiana wcześniej ...

```r
> CAt()
[1] 642
```

... ale trudno zobaczyć, dlaczego działa tak samo, bo cel nie jest już wyrażony w powierzchownej
strukturze kodu. Na przykład, trzeba się chwilę zastanowić, żeby odkryć, że rolą funkcji `g` jest
aktualizacja pamięci. Co więcej, agentka `CAt` jest *czystą relacją wejścia wyjścia, która
wywołuje/odtwarza/stosuje rekurencyjnie samą siebie jako czysty sposób działania*.

Jak sądzisz, *gdzie* jest pamięć tej agentki? W "jej ciele", czy w "środowisku"? I na czym
*dokładnie* polega tutaj różnica między ciałem i środowiskiem?

### O duchach

Jeżeli teraz pozbędziemy się jeszcze, odgrywających ze względu na samą celowość rolę drugorzędną,
wymiarów kondycji i długości życia, to zostaną nam trzy wejścia - sygnał ze środowiska i dwie
komórki pamięci - i trzy wyjścia - ruch i dwie komórki pamięci. Żeby zobaczyć w nim coś ważnego,
maksymalnie uprościmy też problem i przyjmiemy, że każdy z trzech wymiarów/zbiorów/typów może
przyjmować tylko, hm, dwie wartości, przy czym na zbiorze możliwych sygnałów zdefiniujemy
najprostszy nietrywialny porządek, czyli *arbitralnie naniesiemy* na niego *osobliwą strzałkę*.

Jak łatwo policzyć, wszystkich możliwych funkcji ze zbioru zawierającego `2^2^2 = 16` elementów
(tyle jest możliwych kombinacji trzech binarnych wejść) do zbioru `16`-elementowego jest `16^16`,
czyli bardzo, bardzo wiele. Dokładnie *cztery* z tych funkcji odpowiadają tego rodzaju (optymalnemu)
procesowi celowemu, ponieważ osobliwa strzałka może być skierowana w każdą stronę (dwa sposoby), a
nietrywialna celowość jest tutaj możliwa tylko wtedy, gdy konsekwencje ruchów są różne (co też może
zajść na dwa sposoby).

*Celowy ruch jest ekstremalnie unikalny nawet w przypadku ekstremalnie prostych zadań.*

Nic więc dziwnego, że niezwykle rzadko mylimy się co do tego, czy to, co widzimy, słyszymy, lub
czujemy dotykiem *dokądś zmierza* i często prawie natychmiast przynajmniej orientacyjnie
odgadujemy - w bardziej "dzikich" warunkach nierzadko ku własnemu przerażeniu, bo organizmy żywe
stale konkurują o zasoby - *do czego* to coś zmierza. Jednocześnie jest jednak teoretycznie możliwe,
że często mylimy się co do tego, czy jakieś coś do jakiegoś czegoś - być może w jakimś sensie mniej
lub bardziej przypadkowo - *nie* zmierza.

Zwracam uwagę, że użyłem określenia "ekstremalnie unikalne", mając na myśli fakt, że zbiór procesów
celowych to ekstremalnie mała część *teoretycznie* możliwych procesów , a nie określenia
"ekstremalnie rzadkie", które dotyczy *faktycznej relatywnej częstości występowania*. W warunkach
umożliwiających życie, takie procesy mogą stać się i często stają się nawet bardzo częste, ponieważ
organizmy żywe to wystarczająco skuteczne przybliżenia idealnych *rozmnażających się* procesów
celowych. Co więcej, takie procesy mogą być teoretycznie znacznie częstsze, niż nam się zdaje.

*Jedyne*, co decyduje o tym, czy jakiś fizyczny proces albo struktura jest pamięcią, to *rola*, jaką
to coś pełni w ramach jakiegoś innego procesu. I odwrotnie, nie ma czegoś takiego jak pamięć, która
nie jest w ogóle używana jako pamięć; coś takiego może być co najwyżej tylko *potencjalnie*
pamięcią. To samo dotyczy z konieczności *wszystkich* tego rodzaju pojęć, których używamy do opisu
procesów celowych *jako takich*. Na przykad, coś jest albo nie jest *nagrodą* tylko ze względu na
to, w jaki sposób to coś jest powiązane z czymś innym, co możemy konsekwentnie nazywać
*zachowaniem*, *wyborem*, albo *decyzją*. Tego rodzaju funkcje jako role są więc **albo zrealizowane
jednocześnie, albo wcale**. Między innymi dlatego nie jest wcale łatwo je poprawnie i ogólnie
*scharakteryzować*.

W nieco bardziej złożonym środowisku, nasza czysto funkcyjna agentka mogłaby zapisywać
zaktualizowany stan swojej pamięci za każdym razem lub tylko czasami w jakiejś *nowej* strukturze
fizycznej, analogicznie do sposobu, w jaki zwykłe wirusy infekują organizmy żywe, albo w jaki wirusy
komputerowe infekują nowe pliki albo komputery. Gdyby tylko ten proces celowy *odwzorowywał* swój
sposób działania w jakiejś strukturze fizycznej tak, że zainicjowany dzięki temu celowy ruch
używałby tej nowej struktury fizycznej jako swojej pamięci, to *ta sama agentka* trwałaby dalej,
tyle, że - być może tylko częściowo - *w nowym ciele*.

I byłoby wtedy tak, jakby *duch celowości przepływał przez materię*. Tego rodzaju proces, gdyby
rozgrywał się przed naszymi oczami, mógłby być dla nas trudny do zauważenia, nawet, gdyby przebiegał
w przyjaznym dla nas percepcyjnie tempie i w makroskali, i gdyby - dosłownie - obejmował sobą sporą
część materii.

Coś podobnego dzieje się zresztą nieustannie, tyle, że (dla nas) bardzo stopniowo, ze wszystkimi
organizmami żywymi, bo organizmy żywe *wymieniają materię* ciała z materią otoczenia ciała,
*zagarniają materię* otoczenia rosnąc i nieustannie *Się odwzorowywują*, to jest *kształtują
cieleśnie dostępną materię na własne podobieństwo*. Przy czym my, ludzie, jesteśmy gatunkiem
wyjątkowym między innymi pod tym względem, że kształtujemy środowisko na własne podobieństwo, a
dokładniej na podobieństwo własnych pragnień, aspiracji, lęków i uprzedzeń, czyli ostatecznie celów,
na skalę, do której nie zbliża się żaden inny gatunek zwierząt.

To samo widać w pewien sposób, kiedy duch celowości wzbiera i formuje się jak fala, zagarniająca -
jako swój *substrat* - odrębne procesy celowe poszczególnych zwierząt, znajdujących się w mniejszym
albo większym stadzie albo *tłumie*, zwłaszcza gdy przebywają na tyle blisko siebie, by móc się
łatwo komunikować.

Albo w postaci tych złożonych, wewnętrznie powiązanych funkcjonalnie tworów, w skład których wchodzą
hierarchie - budynków, rozmaitej składalnej fizycznej funkcjonalności czy inftrastruktury, i ludzi -
które nazywamy instytucjami.

Albo w rodzinach, klasach, rocznikach, narodach, czy grupach przyjaciół.

Albo w koronach drzew, w których od dziecka zdaje mi się czasem, że widzę niezrozumiałą lecz nie
bezsensowną, płynną mowę; w jakimś kojącym i obcym/znajomym języku.

Czy Tobie też?

A wszystko to za każdym razem zaczyna się dosłownie od *programu*, to jest od DNA. Nasze życie jest
organicznym, a więc tylko przybliżonym, ale jednak *programowaniem świata* i *metaprogramowaniem
Siebie*.

Życie jako takie jest - między innymi - *zrealizowaną organicznie i w przybliżeniu logiką celowego
funkcjonowania*.

Mogę już oddać głos autorom.

### Suttona i Barto koncepcja sensu sensownego życia i być może jeszcze jakiejś reszty

> [...] in 1979 we came to realize that perhaps the simplest of the ideas, which had long been taken
> for granted, had received surprisingly little attention from a computational perspective. This was
> simply the idea of a learning system that *wants* something, that adapts its behavior in order to
> maximize a special signal from its environment. This was the idea of a "hedonistic" learning
> system, or, as we would say now, the idea of reinforcement learning.
>
> [...]
>
> While reinforcement learning had clearly motivated some of the earliest computational studies of
> learning, most of these researchers had gone on to other things, such as pattern classification,
> supervised learning, and adaptive control, or they had abandoned the study of learning
> altogether. As a result, the special issues involved in learning how to get something from the
> environment received relatively little attention.  In retrospect, focusing on this idea was the
> critical step that set this branch of research in motion. Little progress could be made in the
> computational study of reinforcement learning until it was recognized that such a fundamental idea
> had not yet been thoroughly explored. (s. xv)
>
> [...]
>
> The overall problem of learning from interaction to achieve goals is still far from being solved,
> but our understanding of it has improved significantly. We can now place component ideas, such as
> temporal-difference learning, dynamic programming, and function approximation, within a coherent
> perspective with respect to the overall problem.
>
> [...]
>
> We did not reach for the highest possible level of mathematical abstraction and did not rely on a
> theorem–proof format. We tried to choose a level of mathematical detail that points the
> mathematically inclined in the right directions without distracting from the simplicity and
> potential generality of the underlying ideas. (s. xvi)

Pierwszy rozdział, zatytułowany *Reinforcement Learning*, zaczyna się od podrozdziału zatytułowanego
*The Problem*.

*The Problem*!

Autorzy przytaczają na początku kilka codziennych obserwacji, które jasno pokazują, że prawie
wszystkiego, czego się uczymy, uczymy się przez interakcję ze środowiskiem na podstawie zdarzeń
następujących po wykonaniu różnych działań. I to jest, oczywiście, psychologia.

Autorzy podają też samoopis tego, co zdaje im się, że w tej książce robią:

> In this book we explore a computational approach to learning from interaction. Rather than
> directly theorizing about how people or animals learn, we explore idealized learning situations
> and evaluate the effectiveness of various learning methods. (s. 3)

I to jest, oczywiście, ogólna psychologia teoretyczna, albo po prostu psychologia naukowa. W której
chodzi przede wszystkim między innymi o to:

> Reinforcement learning is learning what to do—how to map situations to actions so as to maximize a
> numerical reward signal. The learner is not told which actions to take, as in most forms of
> machine learning, but instead must discover which actions yield the most reward by trying them. In
> the most interesting and challenging cases, actions may affect not only the immediate reward but
> also the next situation and, through that, all subsequent rewards. These two
> characteristics—trial-and-error search and delayed reward are the two most important
> distinguishing features of reinforcement learning.
>
> Reinforcement learning is defined not by characterizing learning methods, but by characterizing a
> learning *problem*. Any method that is well suited to solving that problem, we consider to be a
> reinforcement learning method. (s. 4)

Przypuszczam, że na tym etapie zarówno ogólnopsychologiczny, jak i kategoryjny charakter tego
przedmiotu badań (naukowych, a więc przede wszystkim teoretycznych, czyli również matematycznych)
jest już dla Ciebie oczywisty.

Jeżeli zastanawiasz się, jakie to się ma do niezwykle kosztownej w utrzymaniu i moim zdaniem
niezwykle szkodliwej, ale bardzo ostatnio popularnej i chętnie kupowanej papugi należącej do gatunku
[LLM](https://en.wikipedia.org/wiki/Large_language_model), to następujące uwagi, które Ci autorzy
zapisali w roku 98, a które już wtedy były tylko przypomnieniem kwestii doskonale znanych
specjalistom, powinny rozwiać przynajmniej niektóre Twoje wątpliwości:

> Reinforcement learning is different from *supervised learning*, the kind of learning studied in
> most current research in machine learning, statistical pattern recognition, and artificial neural
> networks. Supervised learning is learning from examples provided by a knowledgable external
> supervisor. This is an important kind of learning, but alone it is not adequate for learning from
> interaction. In interactive problems it is often impractical to obtain examples of desired
> behavior that are both correct and representative of all the situations in which the agent has to
> act. In uncharted territory—where one would expect learning to be most beneficial—an agent must be
> able to learn from its own experience. (s. 4)

Warto do tych uwag może tylko dodać, że LLM-y są (w pewnym sensie) *swoimi własnymi*
nauczycielami. Ta różnica jest jednak powierzchowna, bo tym, co ma w tym kontekście - to jest dla
*rozwiązania jakiegoś problemu* - znaczenie kluczowe, jest *dostępność informacji* nie tylko, jak w
uczeniu się na podstawie wzmocnień, na temat *poprawności niektórych reakcji*, ale również na temat
*poprawnych reakcji*. W porównaniu z tą różnicą, to, w jakim stopniu proces uczenia (się) jest
*zautomatyzowany* jest kwestią trzeciorzędną.

I to są również, oczywiście, fundamentalne różnice *psychologiczne*.

Pierwsze przykłady *rozwiązań problemu* [*uczenia się ze
wzmocnieniem*](https://pl.wikipedia.org/wiki/Uczenie_przez_wzmacnianie), inaczej *uczenia
posiłkowanego*, niestety po polsku nazywanego też czasem moim zdaniem mylnie "uczeniem przez
wzmacnianie", które potem podają autorzy, to: szachista grający na poziomie eksperckim, system
kontrolujący w czasie rzeczywistym parametry działania rafinerii, gazela wstająca niedługo po
urodzeniu z kolan, robot, rozstrzygający między innymi na podstawie aktualnego stanu baterii, czy
powinien odwiedzić kolejny pokój w poszukiwaniu śmieci, i robiący sobie śniadanie Phil
([!](https://en.wikipedia.org/wiki/Somebody_Feed_Phil)).

I to jest czasami informatyka, fizyka, chemia, elektronika, albo biologia, ale to wszystko to też
oczywiście, *zawsze* i *przede wszystkim*, psychologia. W dodatku psychologia nie tylko naukowa -
przede wszystkim dlatego, że (w najlepszym znaczeniu) teoretyczna - ale również *automatycznie
aplikacyjna*.

Co zresztą nie powinno nikogo dziwić, skoro, jak dobitnie pokazuje historia naszej cywilizacji, nie
ma nic bardziej praktycznego niż dobra teoria. Żeby przekonać się na własnej skórze, jak *bardzo*
dobra jest ta teoria, rozważymy teraz nieco inny problem[: ...](./R_42_3.md)

### Przypisy

[^1]: Dawno, dawno temu była taka strona edukacyjna o nazwie "białe kozaczki", na której można było
    podziwiać między innymi zdjęcia osób, które najwyraźniej lubiły przebywać w białych kozaczkach i
    które czasami stały oparte o drogie auta. Pod zdjęciami tego drugiego rodzaju widniał napis
    "zawładnięcie przez dotknięcie".
