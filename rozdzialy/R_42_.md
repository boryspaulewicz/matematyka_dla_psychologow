<!-- -*- coding: utf-8 -*- -->
... oczywiście *środowiska*.

Skądś się te bodźce biorą i w czymś się te reakcje rozgrywają i na coś oddziałują, co nie? A *ciało*
to, za przeproszeniem, pies? 

Właściwie, jak się zastanowić, środowisko nie jest ani szczególnie małe, ani mało znaczące. No ale
(zdawałoby się, że) środowisko to nie fascynujący i tajemniczy *Umysł*; to tylko w większości łatwo
obserwowalne, znane nam wszystkim i przez wszystkich niepsychopatów kochane sklepy Żabka, jakieś
ulice, przystanki i auta, przechodnie i kierowcy, dużo wody, ziemi i powietrza, no i zieleni i
czerwieni. I rozmaitego szumu, i to by było w zasadzie na tyle, bo też - powiedzmy sobie szczerze -
"écru wpadające w limonkę" to nie kolor, to stan chorego umysłu, a ryba jest praktycznie warzywem.

## Trzeci (również śmieszniejszy, ale to jest akurat znacznie bardziej subtelny żart) sposób na psychologię

Jednym z brzemiennych w poważne skutki zdarzeń, które przytrafiło mi się w trakcie dwóch lat
codziennego systematycznego uczenia się różnych rzeczy, o którym to okresie wspominałem już we
wprowadzeniu, było odkrycie w czytelni anglojęzycznej Instytutu Psychologii UJ książki [*An
Introduction to Reinforcement Learning*](https://archive.org/details/rlbook2018/mode/2up) Suttona i
Barto ([pierwsze wydanie](http://incompleteideas.net/book/the-book-1st.html) jest co prawda mniej
aktualne, ale też wspaniałe i znacznie krótsze, więc szybciej wchodzi). Będzie chyba najlepiej,
jeśli zanim sam zacznę o tym gadać, oddam głos tym dwóm cudownym autorom i moim zdaniem (z
konieczności tylko lokalnie, ale jednak) głębokim, wytrawnym i diabelnie przenikliwym
myślicielom. Już obwoluty dowiadujemy się, że (cytaty pochodzą z wydania pierwszego) ...

> This introductory textbook on reinforcement learning is targeted toward engineers and scientists
> in artificial intelligence, operations research, neural networks, and control systems, and we hope
> it will also be of interest to psychologists and neuroscientists.

... się chłopaki mocno przeliczyły. Większość współczesnych psychologów zajmuje się uprawianiem
nauki [performatywnej](https://en.wikipedia.org/wiki/Cargo_cult), pasącej się na ogól z dala od
technicznie złożonych tekstów czy autentycznego systematycznego uczenia się właściwie
czegokolwiek. Ale miałem tyle nie gadać, przepraszam.

Już nic nie mówię.

Normalnie Król Ciszy, zobaczysz.

Czy *słyszę* ironię? Chyba tak, a czemu pytasz?

Albo wiesz co, może jednak zacznę od omówienia trzech przykładów.

## Brudna robota

Wyobraź sobie proszę, że jesteś n-ręką bandytką. Już wyjaśniam.

Zadanie n-rękiej bandytki to wyidealizowana wersja lubianej przez wielu zabawy, polegającej na tym,
że siedzimy lub stoimi przed takim sporym pudłem, ciągniemy za wajchę wystającą z prawej strony,
patrzymy na zmieniające się w kilku okienkach obrazki i rujnujemy sobie i swoim ewentualnym bliskim
życie. Co ciekawe, wiele osób zdaje się sądzić, że adekwatnym określeniem dla tej dualnie
urzekającej formy spędzania wolnego czasu jest słowo "ekscytująca".

Funkcjonalnie, chodzi tu oczywiście o skończony (`n : Nat`) ...

1. zbiór dostępnych działań (`d : Dzialanie`), ...

2. które można wykonywać teoretycznie w nieskończoność (`iteracja : Nat → Dzialanie`) ...

3. i po których następuje cokolwiek, co można ocenić (`nagroda : Dzialanie → Sygnal`) ...

4. posługując się dowolną relacją porządku (`[Porzadek Sygnal]` \{powołanie się na instancję klasy
   `Porzadek`\}).

Wyobraź sobie, że masz nieskończenie dużo czasu, za to żadnych znajomych ani w ogóle nic innego do
roboty, `n = 3`, a nagrodami, jak w kasynie, są wypłaty pieniężne, które mimo szczególnej sytuacji
nadal sobie cenisz. Zaczęłaś od jednokrotnego sprawdzenia każdego z dostępnych działań:

```lean
-- Ten parametryczny typ pozwala wygodnie rozumować na temat jakiegoś czegoś, co może być
-- niedostępne albo niepoznawalne albo bezużyteczne. W Leanie ten typ nazywa się `Option` i ma
-- konstruktory o nazwach `none` i `some`, ale poza tym to (funkcjonalnie) to samo.
inductive Co? (α : Type u) where
  | a_nic         : Co? α
  | a_to (to : α) : Co? α

open Co?

-- 0 ↦ 0, 1 ↦ 1, 2 ↦ 2, _ ↦ właśnie zaczął mi się urlop.
def odwazny_poczatek (n : Nat) : Co? Nat :=
    if n < 3 then (a_to n) else a_nic
```

Przypuszczam, że sposobu działania wyrażeń `if <warunek> then <term> else <term>` nie muszę
tłumaczyć, poza jedną subtelnością - żeby Lean coś takiego zaakceptował, term `warunek` musi być
*rozstrzygalny*. To znaczy, że Lean musi być w stanie automatycznie znaleźć dowód prawdziwości albo
fałszywości tego warunku.

Reguła działania jest tu taka prosta między innymi dlatego, że traktujemy tą sytuację, a dokładniej
to zadanie, jakby nie miało *stanu*. Mówiąc inaczej, ale funkcjonalnie równoważnie, istnieje tylko
jeden stan tego (zewnętrznego wobec nas?) świata. To znaczy, że w tym świecie wszystko działa zawsze
tak samo, niezależnie od tego, co się wcześniej wydarzyło.

Widzimy więc znowu, że w pewnych sytuacjach singleton (tutaj możliwych stanów) zachowuje się tak,
jak będący jego dualnym odpowiednikiem zbiór pusty. W tym przypadku dlatego, że pojęcie stanu
struktury, świata, sytuacji, czy zadania jest tylko wtedy użyteczne, kiedy stany mogą być różne. A
mówiąc inaczej, ale w zasadzie to samo, *pojęcie* stanu *domaga się*, przynajmniej potencjalnej,
tego rodzaju różnorodności, bo kanonicznym zastosowaniem tego pojęcia jest *rozróżnianie* możliwych
stanów (z konieczności oparte na ich własnościach \{jak to rozróżnianie\}).

No więc wyobraź sobie, że na początku *zastosowałaś* `n` razy tego rodzaju *strategię
eksploracyjną*, uzyskując takie oto (funkcjonalnie) zyski, będące jednocześnie (funkcjonalnie)
jedynymi dostępnymi informacjami na temat dynamiki środowiska:

`0 ↦ 665, 1 ↦ 664, 2 ↦ 667`

W tym wypadku możemy jednoznacznie i autorytatywnie stwierdzić, co *powinnaś* zrobić, bo to wynika z
definicji, a wynika z niej, bo to jest definicja *zadania*. Stwierdzenie, że coś się powinno albo
czegoś się nie powinno ma sens *tylko* zakładając jakiś cel, normę, lub wartość, czyli ostatecznie
jakiś cel, a ponieważ cel jako taki jest zawsze pewną preferencją czyli oceną, a ocena jako taka
jest zawsze postawą, funkcjonalnie równoważną pewnej relacji porządku, czyli ostatecznie punktem
widzenia, założenie na temat celu jest
[*nieuzasadnialne*](https://pl.wikipedia.org/wiki/Gilotyna_Hume%E2%80%99a) inaczej niż ze względu na
jakieś inne cele (czyli pewne preferencje, postawy, oceny i zarazem relacje porządku):

*Jeżeli* zależy Ci tylko na pieniądzach (nie oceniam), to zgodnie ze wszystkimi dostępnymi danymi,
*powinnaś* wybrać `2`, ponieważ *najlepszym* albo *racjonalnym* wyborem jest `2` i tylko `2`.

Zwróć proszę uwagę, że w tym kontekście *racjonalny* znaczy *dokładnie* to samo, co *najlepszy*, a
najlepszy znaczy *dokładanie* to samo, co *największy* ze względu na relację porządku, która
odpowiada celowi. Ponadto *rozstrzygnięcie*, który wybór jest w danym momencie racjonalny, wymaga
*pamięci*, która przyjęła tutaj maksymalnie uniwersalną postać *sekwencji reakcji*. Akurat w tym
przykładzie reakcja jest *parą* złożoną z bodźca i działania, ale w ogólnym przypadku będzie
(funkcjonalnie) *trójką*, złożoną z ...

1. bodźca, czyli funkcjonalnie (zwykle ekstremalnie fragmentarycznej) *informacji na temat
aktualnego stanu* (świata), ...

2. działania wykonanego w danej *próbie* i ...

3. stanu *całego* (ale za to tylko rozważanego, więc może być przynajmniej subiektywnie tyci)
   *świata*.

Zwracam też uwagę, że mówimy tu o reakcjach z perspektywy wszechwiędzącej obserwatorki.

Żeby było ciekawiej, zmienimy teraz język na taki, który
[wymaga](https://pl.wikipedia.org/wiki/Odzie%C5%BC_ochronna) założenia co najmniej rękawic do smaru
i oleju. I okularów ochronnych. A właściwie to maska przeciwpyłowa też by nie zaszkodziła. Chodzi o
używany przez wielu psychologów zajmujących się (często niestety nieudolnie) analizą danych język
imperatywny R. Zaczniemy od zdefiniowania w nim prostej *funkcji środowiska*:

```r
## Ta funkcja jest naszym modelem środowiska, w którym może być lepiej lub gorzej, a to, jak w nim
## (nam) jest, zależy od tego, jakie wykonujemy ruchy.

E = function(a){
    c(665, 664, 667)[a + 1]
}
```

Funkcja środowiska pobiera tylko indeks (albo po prostu numer) ruchu (albo po prostu ruch), czyli w
pewnym sensie "decyzję", której wartościami mogą być liczby naturalne od 0 do 2. W ciele tej
funkcji, zdefiniowanym między nawiasami klamrowymi, widzimy wyrażenie (`c(...)`) tworzące *wektor*
trójelementowy (czyli pewnego rodzaju sekwencję), którego wartościami są nagrody/sygnały
odpowiadające każdemu z ruchów/działań. Na tym wektorze wykonywana jest operacja indeksowania, czyli
wskazywania elementu sekwencji za pomocą liczby naturalnej, którą to operację oznaczamy w R używając
nawiasów kwadratowych. Ponieważ w R indeksujemy pozycje w typach sekwencyjnych od 1, a nie od 0, jak
w większości innych języków programowania, do indeksu działania dodajemy 1.

R to dosyć zwyczajny interpretowany język imperatywny, a nie czysty język funkcyjny, dlatego `E` to
*zmienna*, która będzie nazwą tej funkcji od momentu, w którym poddamy ten kod ewaluacji. W
przeciwieństwie do Leana, napisany w skrypcie R-a kod nie zaczyna więc "od razu działać". Widzimy
też, że nie ma tu żadnej jawnej informacji o typach danych, bo (ubogi) system typów języka R został
zaprojektowany do znacznie skromniejszych celów niż formalizacja całej matematyki.

Jeżeli teraz w *wierszu poleceń* interpretera języka R (`> ...`), którego w Leanie nie ma, bo
interakcja z Leanem nie polega na wykonywaniu pętli [REPL](https://pl.wikipedia.org/wiki/REPL),
napiszemy `E(1)` i naciśniemy Enter, zobaczymy następującą *odpowiedź środowiska*:

```r
> E(1)
[1] 664
```

Ten komunikat **czytamy jako**: Sie robi, szefowo (bo R to interpreter pochodzenia wiejskiego, ale w
dobrym znaczeniu), oto wektor jednoelementowy (`[1]`), zawierający liczbę `664`.

## Najprościej, jak się da, żeby zobaczyć, co się da

Ze względu na kwestie, które próbujemy teraz naświetlić, nie jest ważne, czy mamy do wyboru trzy
ruchy, czy dwa, byle tylko był jakiś wybór. Wobec tego dokonamy uproszczenia i pozbędziemy się
jednej z alternatyw, tym bardziej, że zbiory dwuelementowe mają dla nas głębsze, o ile nie zbyt
głębokie znaczenie. Nie będziemy się też bawić w mapowanie *indeksów* ruchów na *same* ruchy, bo to
jest w tym przypadku (funkcjonalnie) jedno i to samo.

Żeby napisać funkcję, która w jakiś sensowny sposób gra w tą grę, *musimy* skorzystać z *pamięci*. Z
powodów, które staną się jasne niebawem, rozwiążemy ten problem w sposób, który bardziej przypomina
styl kodowania w języku funkcyjnym niż w języku imperatywnym:

```r
## Tu określamy, gdzie są jakie
konfitury = c(42, 75)

## Ta prosta funkcja jest naszym roboczym modelem środowiska, w którym to, jak w danym momencie
## jest, zależy od ruchu, który wystąpił w poprzedniej iteracji.
E = function(a){
    konfitury[a]
}

## A to jest funkcja "podmiotu" albo "agentki". Na początku nie ma sygnału ze środowiska (`sygnal =
## NA`), pamięć jest pusta, kondycja ma poziom wyjściowy i agentka jest najmłodszą możliwą wersją
## siebie.
A = function(sygnal = NA, ## To są domyślne wartości parametrów tej funkcji, ...
             pamiec = c(NA, NA),
             wypas  = 0,
             zycia  = 9){ ## ... a to jej ciało:
    ##
    ## Etap wyboru ruchu:
    if(is.na(sygnal)){
        ## Jeżeli nie ma informacji na temat ostatniego sygnału, to musi to być pierwsza próba, w
        ## której arbitralnie wybieramy pierwszy ruch.
        ruch = 1
    }else{
        ## Jeżeli natomiast to nie jest początek interakcji ze środowiskiem ...
        if(zycia == 0){
            ## ... ale to ostatnie życie, to oddajemy wszystko, co nam zostało, ...
            print("Cześć, i dzięki za ryby")
            return(wypas)
        }else{
            ## ... a jeżeli to nie jest ostatnie życie, ...
            if(any(is.na(pamiec))){
                ## ... to jeżeli nie ma jeszcze zapisu pamięciowego sygnału po którymś ruchu, to
                ## wybieramy pierwszy taki ruch, ...
                ruch = which(is.na(pamiec))[1]
            }else{
                ## ... w przeciwnym razie wybieramy ruch o największym zapamiętanym sygnale:
                ruch = which(pamiec == max(pamiec))[1]
            }
        }
    }
    ## Etap przetwarzania sygnału:
    ##
    ## Odbieramy sygnał ze środowiska ...
    sygnal = E(ruch)
    ## .. i oddajemy się konsumpcji:
    wypas = wypas + sygnal
    ## Najadłwszy się, zapamiętujemy sygnał jako własność ostatnio wybranego ruchu, ...
    pamiec[ruch] = sygnal
    ## ... a następnie - trochę się od tego wszystkiego starzejąc - ...
    zycia = zycia - 1
    ## ... aplikujemy Się do dostępnych danych:
    A(sygnal, pamiec, wypas, zycia)
}

A()
```

Cały ten kod możesz wkleić [tutaj](https://rdrr.io/snippets/), lub do zainstalowanego na swoim
komputerze interpretera R. Po wykonaniu ewaluacji (albo po *u-ruchomieniu*) kodu przekonasz się,
że - jak można policzyć (ale komu by się chciało) - po pierwszych dwóch eksploracyjnych wyborach ten
agent wybiera już do samego końca ruch, po którym występuje największy sygnał nagrody:

```r
> A()
[1] "Cześć, i dzięki za ryby"
[1] 642
```

**Przypomnienie o fundamentalnej różnicy między językami funkcyjnymi i imperatywnymi**: W języku R
symbole takie jak tutaj `E`, `A`, `konfitury`, `sygnal`, czy `ruch` nie są *stałymi*, tylko
zmiennymi, które w dodatku mają *inny* charakter niż zmienne w Leanie. Zmienne w Leanie są *tylko
nazwami wejść* (czystych) *funkcji*, a zmienne w R są również *nazwami miejsc w pamięci komputera*,
a poza tym *nie* mają ustalonego typu. Dlatego *w każdej chwili* można *przypisać* - za pomocą
operacji tylko *wyglądającej* jak równość matematyczna - na przykład do zmiennej `E` *jakąkolwiek*
wartość. Zależnie od kontekstu, zastosowanie operacji `=`, którą możemy również oznaczać za pomocą
symbolu `<-`, jest więc albo *nadaniem wartości początkowej*, albo *zmianą* wartości
zmiennej. 

Między innymi dlatego, że ciała funkcji napisanych w R mogą korzystać z dowolnych widocznych w tych
ciałach zmiennych, w tym również ze zmiennych *globalnych*, a wartości zmiennych w R mogą się
zmieniać w trakcie działania programu, funkcje w R mogą mieć i często mają *skutki uboczne*. To
znaczy, że nie muszą zwracać i często nie zwracają tych samych wartości dla tych samych
wejść. Wynika stąd, że funkcje w R zachowują się często bardziej jak procesy *fizyczne* niż jak
"procesy" *logiczne* (inaczej matematyczne).

Kod napisany w R to jednak *również* matematyka. Możemy udowadniać twierdzenia dotyczące sposobu
działania kodu napisanego w językach imperatywnych po prostu dlatego, że to są języki formalne i
napisane w nich programy działają zgodnie z jednoznacznymi, sztywnymi zasadami, czyli zgodnie z
pewną logiką. Różnica polega na tym, że dowodzenie twierdzeń na temat działania programów napisanych
w językach imperatywnym może wymagać uwzględnienia co najmniej modelu komputera kontrolowanego przez
program, jeżeli nie "świata", z którym ten komputer wchodzi w interakcję, a to wymaga zastosowania
logiki *przyczynowej*, którą poznamy kiedy indziej.

Nasza (domniemana) agentka rodzi się w tym małym świecie z bazową "kondycją" (domyślna wartość
zmiennej/parametru/argumentu `wypas` to 0). Częściowo wewnątrz (ciała \{tej funkcji\}) agentki
zdeterminowana jest również - jako przekształcana w ciele, początkowa wartość jednej ze zmiennych -
długość jej "życia". Można więc powiedzieć, że ta agentka rodzi się z wbudowanym "zegarem
biologicznym", który resetuje się do wartości "fabrycznej", kiedy wydaje z siebie pierwotny krzyk
(`A()`). Domyślna, a więc tutaj tylko początkowa wartość sygnału ze środowiska to `NA`, co w języku
R jest standardowym oznaczeniem braku danych (ang. *Not Available*). Czyli ta agentka "rodzi się z
zamkniętymi oczami".

Mogłoby się wydawać, że rodzi się też jako tabula rasa, ale to tylko złudzenie, wynikające z
naiwnego, wąskiego rozumienia takich pojęć jak pamięć i wiedza. Pamięć jest tu co prawda początkowo
pusta, ale jest *dwu*komórkowa, a to znaczy, że jej struktura jest "od urodzenia" *dopasowana do
zadania*. Można powiedzieć, że już samo to jest czymś w rodzaju wbudowanej (uogólnionej) *wiedzy*.
Wiedza musi być w jakiś sposób zapisana fizycznie, a tym, co czyni własność fizyczną (funkcjonalnie)
wiedzą jest *możliwość wnioskowania* z tej własności w połączeniu z *wiedzą o tej możliwości* (tak,
to jest *funkcjonalna definicja rekurencyjna*), bo nie może być wiedzą coś, o czym nie wiemy, że to
wiemy. Ta akurat wbudowana funkcjonalność jest wiedzą, tylko w ogólniejszym sensie, bo chociaż ta
agentka nie wyprowadza wniosków z tej własności, to *jest* (między innymi) wnioskowaniem z tej
własności, bo (ze względu na to zadanie) *jest racjonalnym*, a więc też *logicznym sposobem użycia*
pamięci dwukomórkowej.

Zastanawiasz się nadal, co to za zagadkowo uogólnione pojęcie wiedzy? Otóż *struktura* (ciała
\{funkcji\}) tej agentki jest (między innymi) pewnym *modelem zadania*!

W szczególności, zarówno *konstrukcja* jak i *sposób działania* tej funkcji są dopasowane do
jednoznacznie określonego celu (maksymalizacja skonsumowanej sumy konfitur) i do dynamiki
środowiska, czyli właśnie do zadania. Właściwie jedyna wbudowana "niepewność" to brak wbudowanej w
jakikolwiek sposób (uogólnionej) wiedzy na temat konkretnych wartości sygnałów następujących po
każdym z dostępnych ruchów. Dlatego ta agentka nie musi się prawie w ogóle *uczyć* i dlatego będzie
dla nas pouczającym punktem odniesienia w rozważaniach na temat sensu życia.

## Zawładnięcie przez wchłonięcie[^1]

Jeżeli pozbędziemy się z kodu śladów *intencji autora* (czyli w tym wypadku mnie), zastępując
deksryptywne nazwy zmiennych abstrakcyjnymi symbolami i usuniemy z ciała funkcji co tylko się da,
uzyskamy *C*zystą *A*gen*t*kę (stąd nazwa; poprawną wymowę słychać
[tu](https://youtu.be/CU1HtU5t2O4?si=wNlIIZQ0NEchQdVA)):

```r
f = function(X = c(NA, NA)) ifelse(any(is.na(X)), which(is.na(X)), which(X == max(X)))

g = function(X, Y, Z = NA) if(X == 1){ c(Z, Y[2]) }else{ c(Y[1], Z) }

## https://youtu.be/CU1HtU5t2O4?si=PX07Vz0YRNXuTDMk
CAt = function(X = NA, Y = c(NA, NA), Z = 0, V = 9)
    if(V > 1){ CAt(E(f(Y)), g(f(Y), Y, E(f(Y))), Z + E(f(Y)), V - 1)
    }else{ Z + X }

CAt()
```

Ta agentka działa tak samo, jak agentka omawiana wcześniej ...

```r
> CAt()
[1] 642
```

... ale trudno zobaczyć, dlaczego działa tak samo, bo cel nie jest wyrażony w powierzchownej
strukturze kodu. Na przykład, trzeba się chwilę zastanowić, żeby odkryć, że rolą funkcji `g` jest
aktualizacja pamięci. Co więcej, agentka `CAt` jest *czystą relacją wejścia wyjścia, która
wywołuje/odtwarza/stosuje rekurencyjnie samą siebie jako czysty sposób działania*.

Jak sądzisz, *gdzie* jest pamięć tej agentki? W "jej ciele", czy w "środowisku"? I na czym
*dokładnie* polega tutaj różnica między ciałem i środowiskiem?

Jeżeli pozbędziemy się, odgrywających ze względu na samą celowość rolę drugorzędną, wymiarów
kondycji i długości życia, to zostaną nam trzy wejścia - sygnał ze środowiska i dwie komórki
pamięci - i trzy wyjścia - ruch i dwie komórki pamięci. Żeby zobaczyć w nim coś ważnego, maksymalnie
uprościmy też problem i przyjmiemy, że każdy z trzech wymiarów/zbiorów/typów może przyjmować tylko
*dwie* wartości, przy czym na zbiorze możliwych sygnałów zdefiniujemy najprostszy nietrywialny
porządek, czyli *arbitralnie naniesiemy* na niego *osobliwą strzałkę*.

Jak łatwo policzyć, wszystkich możliwych funkcji ze zbioru zawierającego `2^2^2 = 16` elementów
(tyle jest możliwych kombinacji trzech binarnych wejść) do zbioru `16`-elementowego jest `16^16`,
czyli bardzo, bardzo wiele. Dokładnie *cztery* z tych funkcji odpowiadają tego rodzaju (optymalnemu)
procesowi celowemu, ponieważ osobliwa strzałka może być skierowana w każdą stronę (dwa sposoby), a
nietrywialna celowość jest tutaj możliwa tylko wtedy, gdy konsekwencje ruchów są różne (co też może
zajść na dwa sposoby).

*Celowy ruch jest ekstremalnie unikalny nawet w przypadku ekstremalnie prostych zadań.*

Nic dziwnego, że niezwykle rzadko mylimy się co do tego, czy to, co widzimy, słyszymy, lub czujemy
dotykiem *dokądś zmierza* i często prawie natychmiast dobrze odgadujemy, przynajmniej
orientacyjnie - w bardziej "dzikich" warunkach nierzadko ku własnemu przerażeniu, bo organizmy żywe
stale konkurują o zasoby - *do czego* to coś zmierza. Jest jednak przynajmniej teoretycznie możliwe,
że często mylimy się co do tego, czy jakieś coś do jakiegoś czegoś *nie* zmierza.

Zwracam uwagę, że użyłem określenia "ekstremalnie unikalne", mając na myśli fakt, że zbiór procesów
celowych to ekstremalnie mała część *teoretycznie* możliwych procesów , a nie określenia
"ekstremalnie rzadkie", które dotyczy *faktycznej relatywnej częstości występowania*. W warunkach
umożliwiających życie, takie procesy mogą stać się i często stają się nawet bardzo częste, ponieważ
organizmy żywe to wystarczająco skuteczne przybliżenia idealnych *rozmnażających się* procesów
celowych. Co więcej, takie procesy mogą być teoretycznie znacznie częstsze, niż nam się zdaje.

*Jedyne*, co decyduje o tym, czy jakiś fizyczny proces albo struktura jest pamięcią, to *rola*, jaką
to coś pełni w ramach jakiegoś innego procesu. I odwrotnie, nie ma czegoś takiego jak pamięć, która
nie jest w ogóle używana jako pamięć; coś takiego może być co najwyżej tylko *potencjalnie*
pamięcią. To samo dotyczy z konieczności *wszystkich* pojęć, których używamy do opisu procesów
celowych *jako takich*. Na przykad, coś jest albo nie jest *nagrodą* tylko ze względu na to, w jaki
sposób to coś jest powiązane z czymś innym, co możemy konsekwentnie nazywać *zachowaniem*,
*wyborem*, albo *decyzją*. Tego rodzaju funkcje jako role są *albo zrealizowane jednocześnie, albo
wcale*. Między innymi dlatego nie jest tak łatwo je dobrze ogólnie *scharakteryzować*.

W nieco bardziej złożonym środowisku, nasza czysto funkcyjna agentka mogłaby zapisywać
zaktualizowany stan swojej pamięci za każdym razem lub tylko czasami w jakiejś *nowej* strukturze
fizycznej, analogicznie do sposobu, w jaki zwykłe wirusy infekują organizmy żywe, albo w jaki wirusy
komputerowe infekują nowe pliki czy komputery. Gdyby tylko ten proces celowy *odwzorował*
jednocześnie swój sposób działania w jakiejś strukturze fizycznej tak, że zainicjowany dzięki temu,
podtrzymujący celowość ruch używałby tej nowej struktury fizycznej jako swojej pamięci, to ta
agentka trwałaby dalej, tyle, że - być może tylko częściowo - w nowym ciele.

I byłoby wtedy tak, jakby *duch celowości przepływał przez materię*. Tego rodzaju proces, gdyby
rozgrywał się przed naszymi oczami, mógłby być dla nas trudny do zauważenia, nawet, gdyby rozgrywał
się w percepcyjnie przyjaznym dla nas tempie i w makroskali i - dosłownie - obejmował sobą sporą
część materii.

Coś podobnego dzieje się zresztą nieustannie, tyle, że (dla nas) bardzo stopniowo, ze wszystkimi
organizmami żywymi, bo organizmy żywe nieustannie *wymieniają materię* ciała z materią otoczenia
ciała, *zagarniają materię* otoczenia rosnąc i nieustannie *Się odwzorowywują*, to jest *kształtują
cieleśnie dostępną materię na własne podobieństwo*. Przy czym my, ludzie, jesteśmy gatunkiem
wyjątkowym między innymi pod tym względem, że kształtujemy środowisko na własne podobieństwo, a
dokładniej na podobieństwo własnych pragnień, aspiracji, lęków i uprzedzeń, czyli ostatecznie celów,
na skalę, do której nie zbliża się żaden inny gatunek zwierząt.

To samo widać w pewien sposób, kiedy duch celowości wzbiera i formuje się jak fala, zagarniająca
- jako swój substrat - odrębne procesy celowe jednostek w mniejszym albo większym tłumie zwierząt,
zwłaszcza kiedy przebywają blisko siebie. Albo w postaci tych złożonych, funkcjonalnie powiązanych
tworów, w skład których wchodzą hierarchie budynków, rozmaitej składalnej fizycznej funkcjonalności
czy inftrastruktury i ludzi, które nazywamy instytucjami. 

Albo w rodzinach, klasach, rocznikach, narodach, czy grupach przyjaciół.

Albo w koronach drzew, w których od dziecka zdaje mi się czasem, że widzę niezrozumiałą ale nie
bezsensowną, płynną mowę w jakimś kojącym i obcym - znajomym języku.

Czy Tobie też?

A wszystko to za każdym razem zaczyna się dosłownie od *programu*, to jest od DNA. Nasze życie jest
organicznym, a więc tylko przybliżonym, ale jednak *programowaniem świata* i *metaprogramowaniem
Siebie*.

Życie jako takie jest (między innymi) *zrealizowaną organicznie i w przybliżeniu logiką celowego
funkcjonowania*.

No dobrze, mogę już oddać głos autorom.

## Suttona i Barto koncepcja sensu sensownego życia i być może jeszcze jakiejś reszty

> [...] in 1979 we came to realize that perhaps the simplest of the ideas, which had long been taken
> for granted, had received surprisingly little attention from a computational perspective. This was
> simply the idea of a learning system that *wants* something, that adapts its behavior in order to
> maximize a special signal from its environment. This was the idea of a "hedonistic" learning
> system, or, as we would say now, the idea of reinforcement learning.
>
> [...]
>
> While reinforcement learning had clearly motivated some of the earliest computational studies of
> learning, most of these researchers had gone on to other things, such as pattern classification,
> supervised learning, and adaptive control, or they had abandoned the study of learning
> altogether. As a result, the special issues involved in learning how to get something from the
> environment received relatively little attention.  In retrospect, focusing on this idea was the
> critical step that set this branch of research in motion. Little progress could be made in the
> computational study of reinforcement learning until it was recognized that such a fundamental idea
> had not yet been thoroughly explored. (s. xv)
>
> [...]
>
> The overall problem of learning from interaction to achieve goals is still far from being solved,
> but our understanding of it has improved significantly. We can now place component ideas, such as
> temporal-difference learning, dynamic programming, and function approximation, within a coherent
> perspective with respect to the overall problem.
>
> [...]
>
> We did not reach for the highest possible level of mathematical abstraction and did not rely on a
> theorem–proof format. We tried to choose a level of mathematical detail that points the
> mathematically inclined in the right directions without distracting from the simplicity and
> potential generality of the underlying ideas. (s. xvi)

Pierwszy rozdział, zatytułowany *Reinforcement Learning*, zaczyna się od podrozdziału zatytułowanego
*The Problem*.

*The Problem*!

Autorzy przytaczają na początku kilka codziennych obserwacji, które jasno pokazują, że prawie
wszystkiego, czego się uczymy, uczymy się przez interakcję ze środowiskiem na podstawie zdarzeń
następujących po wykonaniu różnych działań. To jest, oczywiście, psychologia.

Autorzy podają też samoopis tego, co im się zdaje, że w tej książce robią:

> In this book we explore a computational approach to learning from interaction. Rather than
> directly theorizing about how people or animals learn, we explore idealized learning situations
> and evaluate the effectiveness of various learning methods. (s. 3)

To jest, oczywiście, ogólna psychologia teoretyczna, albo po prostu psychologia naukowa. W której
chodzi między innymi o to:

> Reinforcement learning is learning what to do—how to map situations to actions so as to maximize a
> numerical reward signal. The learner is not told which actions to take, as in most forms of
> machine learning, but instead must discover which actions yield the most reward by trying them. In
> the most interesting and challenging cases, actions may affect not only the immediate reward but
> also the next situation and, through that, all subsequent rewards. These two
> characteristics—trial-and-error search and delayed reward are the two most important
> distinguishing features of reinforcement learning.
>
> Reinforcement learning is defined not by characterizing learning methods, but by characterizing a
> learning *problem*. Any method that is well suited to solving that problem, we consider to be a
> reinforcement learning method. (s. 4)

Przypuszczam, że na tym etapie zarówno ogólnopsychologiczny jak i kategoryjny charakter tego
przedmiotu badań (naukowych, a więc przede wszystkim teoretycznych, czyli również matematycznych)
jest dla Ciebie oczywisty.

Jeżeli zastanawiasz się, jakie to się ma do niezwykle kosztownej w utrzymaniu i moim zdaniem
niezwykle szkodliwej, ale bardzo ostatnio popularnej i chętnie kupowanej papugi należącej do gatunku
[LLM](https://en.wikipedia.org/wiki/Large_language_model), następujące uwagi, które Ci autorzy
zapisali w roku 98 i które już wtedy były tylko przypomnieniem kwestii doskonale znanych
specjalistom, powinny rozwiać przynajmniej niektóre Twoje wątpliwości:

> Reinforcement learning is different from *supervised learning*, the kind of learning studied in
> most current research in machine learning, statistical pattern recognition, and artificial neural
> networks. Supervised learning is learning from examples provided by a knowledgable external
> supervisor. This is an important kind of learning, but alone it is not adequate for learning from
> interaction. In interactive problems it is often impractical to obtain examples of desired
> behavior that are both correct and representative of all the situations in which the agent has to
> act. In uncharted territory—where one would expect learning to be most beneficial—an agent must be
> able to learn from its own experience. (s. 4)

Może warto tylko dodać, że LLM-y są (w pewnym sensie) *swoimi własnymi* nauczycielami, ale ta
różnica jest powierzchowna, bo tym, co ma tu znaczenie kluczowe, jest *dostępność informacji na
temat poprawnych reakcji*, a nie to, czy proces uczenia (się) jest *zautomatyzowany*.

I to też są, oczywiście, fundamentalne różnice *psychologiczne*.

Pierwsze przykłady *rozwiązań problemu* [*uczenia się ze
wzmocnieniem*](https://pl.wikipedia.org/wiki/Uczenie_przez_wzmacnianie), inaczej *uczenia
posiłkowanego*, niestety po polsku nazywanego też czasem moim zdaniem mylnie "uczeniem przez
wzmacnianie", które potem podają autorzy, to szachista grający na poziomie eksperckim, system
kontrolujący w czasie rzeczywistym parametry działania rafinerii, gazela wstająca niedługo po
urodzeniu z kolan, robot, rozstrzygający między innymi na podstawie aktualnego stanu baterii, czy
powinien odwiedzić kolejny pokój w poszukiwaniu śmieci i robiący sobie śniadanie Phil
([!](https://en.wikipedia.org/wiki/Somebody_Feed_Phil)).

To wszystko to oczywiście - par excellance - psychologia, w dodatku nie tylko naukowa - przede
wszystkim dlatego, że (w najlepszym znaczeniu) teoretyczna - ale również *automatycznie
aplikacyjna*.

Co zresztą nie powinno nikogo dziwić, skoro - jak dobitnie pokazuje historia naszej cywilizacji -
nie ma nic bardziej praktycznego niż dobra teoria. Żeby przekonać się, jak *bardzo* dobra jest ta
teoria, rozważymy teraz nieco inny problem[:](./R_42__.md)

TODO Ilustrować przykładami i komentować to, co pojawia się w SiB do s. 7

TODO eksploracja-eksploatacja za SiB (s. 4-5)

TODO rozważanie całego problemu celowej interakcji, za SiB (s. 4-5)

TODO konieczne założenia przyczynowe w RELE

TODO homomorfizm
planowania działań.

TODO Sutton i Barto nie wiedząc o tym odkryli "wielkie TO".

TODO GIBSON

Postrzeganie świata w kategoriach interfejsu programistycznego. Uogólnione rozumienie programowania
jako fizycznego rozwiązywania problemów.

### Przypisy

[^1]: Dawno, dawno temu była też taka strona edukacyjna o nazwie "białe kozaczki", na której można
    było podziwiać między innymi zdjęcia osób, które często przebywały w białych kozaczkach i które
    czasami stały oparte o jakieś drogie auta. Pod zdjęciami tego drugiego rodzaju widniał napis
    "zawładnięcie przez dotknięcie".
